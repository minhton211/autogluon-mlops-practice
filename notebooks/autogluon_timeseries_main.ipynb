{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "# In Jupyter, use cwd() instead of __file__\n",
    "ROOT = pathlib.Path.cwd().parent.resolve()\n",
    "sys.path.append(str(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "config = {\n",
    "    \"datasets\": [\"TramCanGio\"],\n",
    "    \"target\": \"EC[g/l]\",\n",
    "    \"resample_freq\": \"h\",\n",
    "    \"resample_agg\": \"max\",\n",
    "    \"prediction_length\": 24,\n",
    "    \"eval_metric\": \"MSE\",\n",
    "    \"presets\": \"fast_training\",\n",
    "    \"time_limit\": 60,\n",
    "}\n",
    "\n",
    "\n",
    "config[\"name\"] = f\"autogluon_{config['resample_freq']}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scripts.dataloader.factory import load_datasets\n",
    "\n",
    "df = load_datasets(config[\"datasets\"], resample_freq=config[\"resample_freq\"], resample_agg=config[\"resample_agg\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.timeseries import TimeSeriesDataFrame\n",
    "\n",
    "long_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"station\",\n",
    "    timestamp_column=\"ds\"\n",
    ")\n",
    "\n",
    "# train_df, test_df = long_data.train_test_split(config[\"prediction_length\"] * 3)\n",
    "train_df = long_data.slice_by_timestep(0, -config[\"prediction_length\"]*3)\n",
    "test_df = long_data.slice_by_timestep(-config[\"prediction_length\"]*3, None)\n",
    "\n",
    "train_df.tail(), test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "for station in train_df.item_ids:\n",
    "\n",
    "    train_ts = train_df.loc[station]\n",
    "    test_ts  = long_data.loc[station]\n",
    "\n",
    "    # Single plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    # Plot test\n",
    "    ax.plot(test_ts.index, test_ts.values, label=\"Test\")\n",
    "\n",
    "    # Highlight forecast horizon\n",
    "    ax.axvspan(\n",
    "        train_ts.index[-1],       # boundary between past and future\n",
    "        test_ts.index[-1],        # end of test data\n",
    "        color=\"orange\",\n",
    "        alpha=0.3,\n",
    "        label=\"Forecast horizon\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{station} – Test (Historical + Future)\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"BASWAP\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=config[\"prediction_length\"],\n",
    "    path=f\"{ROOT}/models/autogluonTS/{config[\"name\"]}\",\n",
    "    target=config[\"target\"],\n",
    "    eval_metric=config[\"eval_metric\"],\n",
    "    freq=config[\"resample_freq\"],\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_df,\n",
    "    presets=config[\"presets\"],\n",
    "    time_limit=config[\"time_limit\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results_dict = predictor.fit_summary()\n",
    "\n",
    "rows = []\n",
    "for m in predictor.model_names():\n",
    "    rows.append({\n",
    "        \"model\": m,\n",
    "        \"model_type\": results_dict[\"model_types\"].get(m),\n",
    "        \"performance\": results_dict[\"model_performance\"].get(m),  \n",
    "        \"is_best\": (m == results_dict.get(\"model_best\")),\n",
    "        \"fit_time\": results_dict[\"model_fit_times\"].get(m),\n",
    "        \"pred_time\": results_dict[\"model_pred_times\"].get(m),\n",
    "        \"hyperparams\": json.dumps(results_dict[\"model_hyperparams\"].get(m, {})),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "summary_table = wandb.Table(data=summary_df, columns=summary_df.columns.tolist())\n",
    "wandb.log({\"train_summary\": summary_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get leaderboard\n",
    "lb = predictor.leaderboard(\n",
    "    test_df,\n",
    "    extra_metrics=[\"MAE\", \"MSE\", \"RMSE\"],\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "# Convert to W&B table\n",
    "lb_table = wandb.Table(dataframe=lb)\n",
    "\n",
    "# Log\n",
    "wandb.log({\"test_leaderboard\": lb_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = []\n",
    "# for model in predictor.model_names():\n",
    "#     result = predictor.evaluate(test_df, metrics=[\"MAE\", \"MSE\", \"RMSE\"], model=model)\n",
    "#     row = {\"model\": model, **result}\n",
    "#     rows.append(row)\n",
    "\n",
    "# test_result = pd.DataFrame(rows)\n",
    "\n",
    "# table = wandb.Table(data=test_result, columns=[\"model\", \"MAE\", \"MSE\", \"RMSE\"])\n",
    "# wandb.log({\"test_results\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "H = config[\"prediction_length\"]\n",
    "input_window = 2 * H\n",
    "\n",
    "rows = []\n",
    "\n",
    "model_names = predictor.model_names()\n",
    "\n",
    "for model in model_names:\n",
    "\n",
    "    abs_errors_per_lead = [[] for _ in range(H)]\n",
    "    sq_errors_per_lead  = [[] for _ in range(H)]\n",
    "\n",
    "    for item in test_df.item_ids:\n",
    "\n",
    "        series_true = test_df.loc[item][config[\"target\"]]\n",
    "\n",
    "        t_arr = np.asarray(series_true)\n",
    "        N = len(t_arr)\n",
    "        if N < input_window + H:\n",
    "            continue\n",
    "\n",
    "        num_rolls = N - (input_window + H) + 1\n",
    "\n",
    "        for roll in range(num_rolls):\n",
    "\n",
    "            input_start = 0\n",
    "            input_end   = roll + input_window\n",
    "            future_start = input_end\n",
    "            future_end   = input_end + H\n",
    "\n",
    "            # --- FIX: AutoGluon REQUIRES a TimeSeriesDataFrame, not a Series ---\n",
    "            input_slice = test_df.loc[[item]].iloc[input_start:input_end]\n",
    "\n",
    "            # Predict only this item\n",
    "            pred_df = predictor.predict(input_slice, model=model)\n",
    "\n",
    "            # AG output: MultiIndex → (item, timestamp) → 'mean'\n",
    "            pred_series = pred_df.loc[item][\"mean\"].values\n",
    "\n",
    "            true_future = t_arr[future_start:future_end]\n",
    "\n",
    "            min_len = min(len(true_future), len(pred_series))\n",
    "            if min_len == 0:\n",
    "                continue\n",
    "\n",
    "            for j in range(min_len):\n",
    "                t = true_future[j]\n",
    "                p = pred_series[j]\n",
    "                if np.isnan(t) or np.isnan(p):\n",
    "                    continue\n",
    "\n",
    "                err = p - t\n",
    "                abs_errors_per_lead[j].append(abs(err))\n",
    "                sq_errors_per_lead[j].append(err ** 2)\n",
    "\n",
    "    # --- Compute metrics for each lead ---\n",
    "    for j in range(H):\n",
    "        abs_list = abs_errors_per_lead[j]\n",
    "        sq_list  = sq_errors_per_lead[j]\n",
    "\n",
    "        mae  = float(np.mean(abs_list)) \n",
    "        mse  = float(np.mean(sq_list))  \n",
    "        rmse = float(np.sqrt(mse))      \n",
    "\n",
    "        rows.append({\n",
    "            \"model\": model,\n",
    "            \"time_step\": str(j + 1),\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse\n",
    "        })\n",
    "\n",
    "    # --- Add weighted aggregate row ---\n",
    "    df_tmp = pd.DataFrame([r for r in rows if r[\"model\"] == model])\n",
    "\n",
    "    avg_mae = float(np.average(df_tmp[\"MAE\"]))\n",
    "    avg_mse = float(np.average(df_tmp[\"MSE\"]))\n",
    "    avg_rmse = float(np.sqrt(avg_mse))\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": model,\n",
    "        \"time_step\": \"avg\",\n",
    "        \"MAE\": avg_mae,\n",
    "        \"MSE\": avg_mse,\n",
    "        \"RMSE\": avg_rmse\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "metrics_table = wandb.Table(data=metrics_df, columns=metrics_df.columns.tolist())\n",
    "wandb.log({\"rolling_stepwise_test_results\": metrics_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in predictor.model_names():\n",
    "    predictions = predictor.predict(test_df[:-config[\"prediction_length\"]], model=model)\n",
    "    fig = predictor.plot(test_df, predictions, max_history_length=config[\"prediction_length\"]*7)\n",
    "\n",
    "    wandb.log({f\"plot_test_{model}\": wandb.Image(fig)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "\n",
    "model_path = r\"C:\\Users\\PC\\Desktop\\Tech\\VGU\\BASWAP\\baswap\\models\\autogluonTS\\autogluon_h\"\n",
    "\n",
    "predictor = TimeSeriesPredictor.load(path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in predictor.model_names():\n",
    "    predictions = predictor.predict(test_df[:-config[\"prediction_length\"]], model=model)\n",
    "    fig = predictor.plot(test_df, predictions, max_history_length=config[\"prediction_length\"]*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "H = config[\"prediction_length\"]\n",
    "input_window = 2 * H\n",
    "\n",
    "rows = []\n",
    "\n",
    "model_names = predictor.model_names()\n",
    "\n",
    "for model in model_names:\n",
    "\n",
    "    abs_errors_per_lead = [[] for _ in range(H)]\n",
    "    sq_errors_per_lead  = [[] for _ in range(H)]\n",
    "\n",
    "    for item in test_df.item_ids:\n",
    "\n",
    "        series_true = test_df.loc[item][config[\"target\"]]\n",
    "\n",
    "        t_arr = np.asarray(series_true)\n",
    "        N = len(t_arr)\n",
    "        if N < input_window + H:\n",
    "            continue\n",
    "\n",
    "        num_rolls = N - (input_window + H) + 1\n",
    "\n",
    "        for roll in range(num_rolls):\n",
    "\n",
    "            input_start = 0\n",
    "            input_end   = roll + input_window\n",
    "            future_start = input_end\n",
    "            future_end   = input_end + H\n",
    "\n",
    "            # --- FIX: AutoGluon REQUIRES a TimeSeriesDataFrame, not a Series ---\n",
    "            input_slice = test_df.loc[[item]].iloc[input_start:input_end]\n",
    "\n",
    "            # Predict only this item\n",
    "            pred_df = predictor.predict(input_slice, model=model)\n",
    "\n",
    "            # AG output: MultiIndex → (item, timestamp) → 'mean'\n",
    "            pred_series = pred_df.loc[item][\"mean\"].values\n",
    "\n",
    "            true_future = t_arr[future_start:future_end]\n",
    "\n",
    "            min_len = min(len(true_future), len(pred_series))\n",
    "            if min_len == 0:\n",
    "                continue\n",
    "\n",
    "            for j in range(min_len):\n",
    "                t = true_future[j]\n",
    "                p = pred_series[j]\n",
    "                if np.isnan(t) or np.isnan(p):\n",
    "                    continue\n",
    "\n",
    "                err = p - t\n",
    "                abs_errors_per_lead[j].append(abs(err))\n",
    "                sq_errors_per_lead[j].append(err ** 2)\n",
    "\n",
    "    # --- Compute metrics for each lead ---\n",
    "    for j in range(H):\n",
    "        abs_list = abs_errors_per_lead[j]\n",
    "        sq_list  = sq_errors_per_lead[j]\n",
    "\n",
    "        mae  = float(np.mean(abs_list)) \n",
    "        mse  = float(np.mean(sq_list))  \n",
    "        rmse = float(np.sqrt(mse))      \n",
    "\n",
    "        rows.append({\n",
    "            \"model\": model,\n",
    "            \"lead_time\": str(j + 1),\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse\n",
    "        })\n",
    "\n",
    "    # --- Add weighted aggregate row ---\n",
    "    df_tmp = pd.DataFrame([r for r in rows if r[\"model\"] == model and r[\"lead_time\"] != \"avg\"])\n",
    "\n",
    "    avg_mae = float(np.average(df_tmp[\"MAE\"]))\n",
    "    avg_mse = float(np.average(df_tmp[\"MSE\"]))\n",
    "    avg_rmse = float(np.sqrt(avg_mse))\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": model,\n",
    "        \"lead_time\": \"avg\",\n",
    "        \"MAE\": avg_mae,\n",
    "        \"MSE\": avg_mse,\n",
    "        \"RMSE\": avg_rmse\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "metrics_df[metrics_df[\"model\"] == \"WeightedEnsemble\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-ml (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
